---
jupyter:
  jupytext:
    text_representation:
      extension: .Rmd
      format_name: rmarkdown
      format_version: '1.2'
      jupytext_version: 1.16.1
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

# init

```{python}
import pandas as pd
import geopandas as gpd
import warnings
import numpy as np
```

## configs

```{python}
PATH = [
        "/home/shaghayegh/Downloads/project/NY/yellow_tripdata_2023-01.parquet"
        ,"/home/shaghayegh/Downloads/project/NY/yellow_tripdata_2023-02.parquet"
        ,"/home/shaghayegh/Downloads/project/NY/yellow_tripdata_2023-03.parquet"
        ,"/home/shaghayegh/Downloads/project/NY/yellow_tripdata_2023-04.parquet"
       ]
```

```{python}
PATH_ZONES = "/home/shaghayegh/Downloads/project/NY/taxi_zones/taxi_zones.shp"
```

# load data

```{python}
df_zones = gpd.read_file(PATH_ZONES)
```

```{python}
df = pd.concat(pd.read_parquet(path) for path in PATH)
```

# concat data

<!-- #region jp-MarkdownHeadingCollapsed=true -->
## show data
<!-- #endregion -->

```{python}
df
```

```{python}
df.iloc[0]
```

<!-- #region jp-MarkdownHeadingCollapsed=true -->
# data preprocessing
<!-- #endregion -->

```{python}
df['Date'] = pd.to_datetime(df['tpep_pickup_datetime']).dt.date
df
```

```{python}
date_min = pd.Timestamp('2023-01-01').date()
date_max = pd.Timestamp('2023-04-30').date()
df= df[df['Date'] >= date_min]
df = df[date_max >= df['Date']]
df
```

```{python}
df['Week_days'] = df['tpep_pickup_datetime'].dt.day_name()
df
```

```{python}
df.rename(columns={'PULocationID': 'LocationID'}, inplace=True)
```

```{python}
merged_df = pd.merge(df, df_zones[['LocationID', 'zone']], on='LocationID')
merged_df[['LocationID', 'zone']]
```

```{python}
merged_df
```

```{python}
warnings.filterwarnings('ignore')
```

<!-- #region jp-MarkdownHeadingCollapsed=true -->
# top 50 areas 
<!-- #endregion -->

```{python}
pop_area_df = df.groupby('LocationID')['VendorID'].count().sort_values(ascending=False)
pop_area_df.head(50)
```

```{python}
pop_area_df = merged_df.groupby('zone')['VendorID'].count().sort_values(ascending=False)
pop_area_df
```

```{python}
pop_area_df = merged_df.groupby('zone')['VendorID'].count().sort_values(ascending=False).reset_index(name='count')
pop_area_df.head(50)
```

```{python}
top_50_areas = pop_area_df.head(50)['zone'].tolist()
top_50_areas
```

```{python}
pop_area_df = merged_df.groupby('zone')['LocationID'].count().sort_values(ascending=False).reset_index(name='count')
pop_area_df.head(50)
```

# trips per area and date

```{python}
Daily_trips_df = merged_df.groupby(['Date', 'LocationID', 'Week_days']).size().reset_index(name='Daily_trips')

Daily_trips_df
```

## 10 days df of top 50 areas 

```{python}
a = merged_df[merged_df['zone'].isin(top_50_areas)]
top_50_areas_id = set(a['LocationID'])
top_50_areas_id
```

```{python}
top_50_areas_df = Daily_trips_df[Daily_trips_df['LocationID'].isin(top_50_areas_id)]
top_50_areas_df
```

```{python}
#all_trips_df['1_day_lag'] = all_trips_df.rolling(window=2, on = 'Daily_trips')
#all_trips_df
```

```{python}
#all_trips_df['1_day_lag'] = all_trips_df['Daily_trips'].rolling(window=2).mean()
#all_trips_df
```

```{python}
top_50_areas_df['1_day_lag'] = (
    top_50_areas_df
    .groupby('LocationID')['Daily_trips']
    .rolling(window=2)
    .apply(lambda x: x.iloc[0] if len(x) >= 1 else None)
    .reset_index(level=0, drop=True)
)
top_50_areas_df
```

```{python}
#all_trips_df['1_day_lag'] = all_trips_df.groupby('LocationID')['Daily_trips'].transform(lambda x: x.shift(1))
```

```{python}
top_50_areas_df['2_days_lag'] = (
    top_50_areas_df
    .groupby('LocationID')['Daily_trips']
    .rolling(window=3)
    .apply(lambda x: x.iloc[0] if len(x) >= 1 else None)
    .reset_index(level=0, drop=True)
)
top_50_areas_df
```

```{python}
top_50_areas_df['3_days_lag'] = (
    top_50_areas_df
    .groupby('LocationID')['Daily_trips']
    .rolling(window=4)
    .apply(lambda x: x.iloc[0] if len(x) >= 1 else None)
    .reset_index(level=0, drop=True)
)
top_50_areas_df = top_50_areas_df.dropna()
top_50_areas_df
```

```{python}
top_50_areas_df['4_days_lag'] = (
    top_50_areas_df
    .groupby('LocationID')['Daily_trips']
    .rolling(window=5)
    .apply(lambda x: x.iloc[0] if len(x) >= 1 else None)
    .reset_index(level=0, drop=True)
)
top_50_areas_df
```

```{python}
top_50_areas_df['5_days_lag'] = (
    top_50_areas_df
    .groupby('LocationID')['Daily_trips']
    .rolling(window=6)
    .apply(lambda x: x.iloc[0] if len(x) >= 1 else None)
    .reset_index(level=0, drop=True)
)
top_50_areas_df
```

```{python}
top_50_areas_df['6_days_lag'] = (
    top_50_areas_df
    .groupby('LocationID')['Daily_trips']
    .rolling(window=7)
    .apply(lambda x: x.iloc[0] if len(x) >= 1 else None)
    .reset_index(level=0, drop=True)
)
top_50_areas_df
```

```{python}
top_50_areas_df['7_days_lag'] = (
    top_50_areas_df
    .groupby('LocationID')['Daily_trips']
    .rolling(window=8)
    .apply(lambda x: x.iloc[0] if len(x) >= 1 else None)
    .reset_index(level=0, drop=True)
)
top_50_areas_df
```

```{python}
top_50_areas_df['8_days_lag'] = (
    top_50_areas_df
    .groupby('LocationID')['Daily_trips']
    .rolling(window=9)
    .apply(lambda x: x.iloc[0] if len(x) >= 1 else None)
    .reset_index(level=0, drop=True)
)
top_50_areas_df
```

```{python}
top_50_areas_df['9_days_lag'] = (
    top_50_areas_df
    .groupby('LocationID')['Daily_trips']
    .rolling(window=10)
    .apply(lambda x: x.iloc[0] if len(x) >= 1 else None)
    .reset_index(level=0, drop=True)
)
top_50_areas_df
```

```{python}
top_50_areas_df['10_days_lag'] = (
    top_50_areas_df
    .groupby('LocationID')['Daily_trips']
    .rolling(window=11)
    .apply(lambda x: x.iloc[0] if len(x) >= 1 else None)
    .reset_index(level=0, drop=True)
)
top_50_areas_df = top_50_areas_df.dropna()
top_50_areas_df
```

## top 50 areas data frame

```{python}
top_50_areas_df.to_csv('/home/shaghayegh/class/New York project/top50areas.csv', index=False)
```

```{python}
top_50_areas_df = pd.read_csv('/home/shaghayegh/class/New York project/top50areas.csv')
top_50_areas_df
```

```{python}

```
